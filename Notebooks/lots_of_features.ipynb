{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature overload\n",
    "this is just to see what happens if a ton of features are shoved into the model. This will include avg embedding per news article (300 dimensions), keywords tfidf (50 dimensions), and article text tfidf (2000 dimensions). Didn't work. Probably overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "%matplotlib inline\n",
    "nlp = spacy.load('en')\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_data = pd.read_pickle('../Data/EWS_Published Project_Listing_DD.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../Data/Feedly_Processed_DF_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data/Labeled_Data/sectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_sectors = data.merge(train_data[['article_id', 'Sectors', 'cl_Sector', 'top_sector']],\n",
    "                    on='article_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix sector labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_sectors.astype({'Sectors':str})\n",
    "data_with_sectors[data_with_sectors['Sectors'] == 'transport'] = 'Transport'\n",
    "data_with_sectors[data_with_sectors['Sectors'] == 'Not a project'] = None\n",
    "data_with_sectors[data_with_sectors['Sectors'] == '0'] = None\n",
    "data_with_sectors['Sectors'] = data_with_sectors['Sectors'].str.upper()\n",
    "data_with_sectors['Sectors'] = data_with_sectors['Sectors'].apply(lambda x: None if not x else x.replace('TRADE AND INDUSTRY','INDUSTRY AND TRADE'))\n",
    "data_with_sectors['Sectors'] = data_with_sectors['Sectors'].apply(lambda x: None if not x else x.replace('\\n',''))\n",
    "data_with_sectors['Sectors'] = data_with_sectors['Sectors'].apply(lambda x: None if not x else ','.join([x.strip() for x in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge labels back with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = data_with_sectors['Sectors'].str.get_dummies(',').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_sectors = pd.concat([data_with_sectors, data_with_sectors['Sectors'].str.get_dummies(',')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix article_keywords\n",
    "data_with_sectors['article_keywords'] = data_with_sectors['article_keywords'].apply(lambda x: [] if not x or type(x) != list else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Language dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(r'../dependencies/wiki-news-300d-1M.vec')\n",
    "with open(r'stop_words.txt', 'r') as f:\n",
    "    stop_words = set(f.read().strip().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_sectors['spacy_text'] = data_with_sectors['article_text'].apply(lambda x: nlp('') if not x else nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding(spac_text):\n",
    "    embed=[]\n",
    "    for tok in spac_text:\n",
    "        if tok not in stop_words and tok.text.lower() in w2v:\n",
    "            embed.append(w2v[tok.text.lower()])\n",
    "    return np.mean(embed, axis=0) if len(embed) > 0 else [0]*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_sectors['avg_embedding'] = data_with_sectors['spacy_text'].apply(lambda x: create_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_with_sectors['text_without_sw'] = data_with_sectors['spacy_text'].apply(lambda x: ' '.join([y.text for y in x if y.text.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_sectors['keywords'] = data_with_sectors['article_keywords'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features (embedding, text, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data_with_sectors, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv_1 = TfidfVectorizer(ngram_range = (1,3), max_features=2000)\n",
    "tv_2 = TfidfVectorizer(ngram_range = (1,2), max_features=50)\n",
    "txt_feat = tv_1.fit_transform(train['text_without_sw'])\n",
    "kw_feat = tv_2.fit_transform(train['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.hstack([ np.vstack(train['avg_embedding'])])\n",
    "train_y = train[classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_txt_feat = tv_1.transform(test['text_without_sw'])\n",
    "test_kw_feat = tv_2.transform(test['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x =  np.hstack([np.vstack(test['avg_embedding'])])\n",
    "test_y = test[classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = rf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = np.transpose([[1 if y[1] > 0.5 else 0 for y in x] for x in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (metrics.classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39325842696629215"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.accuracy_score(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
